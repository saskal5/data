{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5\n",
    "\n",
    "For this homework, we are going to work with [*Indoor User Movement Prediction from RSS data*](https://archive.ics.uci.edu/ml/datasets/Indoor+User+Movement+Prediction+from+RSS+data) dataset from UCI.  The homework is due Friday, December 21st midnight. \n",
    "\n",
    "## Task 1\n",
    "\n",
    "Download the dataset and unzip it in under a subdirectory of `data` folder named `rss_data`.\n",
    "\n",
    "The files we are interested is in the subfolder `dataset`.  Each of these files whose names that start with `MovementAAL_RSS_` contain data collected from indivuduals. Each of these files represent a single data point.  There are 314 of these files, and hence, you have 314 data points.  Each file has 4 columns but the number of rows change from file to file.  \n",
    "\n",
    "There is also a file named `MovementALL_target.csv` in that folder. This file tells us the class each of these measurements are assigned. Some of these measurements are labelled with +1 and some are labelled with -1.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Construct a SVM model that separates +1 labelled data points from -1 data points.  You must first solve the problem that these datapoints do not have the same number of rows even though they all have the same number of columns. \n",
    "\n",
    "## Task 3\n",
    "\n",
    "Using [Keras](https://keras.io/getting-started/sequential-model-guide/) write a neural network model that separates +1 labelled data points from -1 data points.\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. You must document each step of your tasks: what are you doing, why are you doing it, what problems you encountered and how you solved it.  All of these must be explained and documented.  Solutions without sufficient documentations will be penalized accordingly. 50% of your points will come from your code, while the other 50% will come from your explanations.\n",
    "\n",
    "1. You can use MS Excel to inspect the files, but loading them up to python using pandas and inspecting them there under jupyter is easier.\n",
    "\n",
    "3. Put the data in a separate subfolder of your `data` folder and rename it `rss_data`. I'll take points off if the data is not saved under the correct place.\n",
    "\n",
    "1. For both of Task 2 and Task 3, you must split your data into a train and test set, and then evaluate the accuracy of your model on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import nan as Nan\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv('C:/Users/azad/Desktop/Data Analysis in Fund. Sciences/github.com/data/rss_data/MovementAAL_target.csv', \n",
    "                             names=('sequence_ID', 'class_label'), \n",
    "                             skiprows=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(seq_id):\n",
    "    return pd.read_csv('C:/Users/azad/Desktop/Data Analysis in Fund. Sciences/github.com/data/rss_data/MovementAAL_RSS_%s.csv' % seq_id, \n",
    "                           names=('RSS_anchor1', 'RSS_anchor2','RSS_anchor3', 'RSS_anchor4'), \n",
    "                           skiprows=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(df):\n",
    "    frames = []\n",
    "    target = []\n",
    "    for idx, row in df.iterrows():\n",
    "        data = get_dataframe(row['sequence_ID'])\n",
    "        frames.append(data)\n",
    "        arr = [row['class_label']] * len(data)\n",
    "        target += arr\n",
    "        \n",
    "    return frames, target\n",
    "\n",
    "data_test, target_test = create_data(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_test\n",
    "y = target_test\n",
    "\n",
    "for i in range(0,314):\n",
    "    length = len(X[i])\n",
    "    length1 = 129 - length\n",
    "    for j in range(0,length1):\n",
    "        X[i] = X[i].append(pd.Series([np.nan]), ignore_index = True)\n",
    "    X[i] = X[i].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = [None]*4\n",
    "xs = np.zeros((314,4))\n",
    "\n",
    "for j in range(0,314):\n",
    "    for i in range(0,4):\n",
    "        if(i==0):\n",
    "            total[0] = np.nansum(X[j].loc[:,'RSS_anchor1'])\n",
    "        elif(i==1):\n",
    "            total[1] = np.nansum(X[j].loc[:,'RSS_anchor2'])\n",
    "        elif(i==2):\n",
    "            total[2] = np.nansum(X[j].loc[:,'RSS_anchor3'])\n",
    "        else:\n",
    "            total[3] = np.nansum(X[j].iloc[:,3:4])\n",
    "    xs[j] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.drop('sequence_ID', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azad\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[24, 16],\n",
       "       [12, 27]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = df_target\n",
    "\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "train_xs, test_xs, train_ys, test_ys = train_test_split(xs,ys,test_size=0.25)\n",
    "classifier.fit(train_xs,train_ys)\n",
    "\n",
    "predicted_ys = classifier.predict(test_xs)\n",
    "confusion_matrix(test_ys,predicted_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455696202531646"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_ys,predicted_ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3: Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azad\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from xmltodict import parse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs, test_xs, train_ys, test_ys = train_test_split(xs,ys,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "235/235 [==============================] - 0s 833us/step - loss: 6.7459 - acc: 0.4894\n",
      "Epoch 2/40\n",
      "235/235 [==============================] - 0s 51us/step - loss: 4.6031 - acc: 0.4809\n",
      "Epoch 3/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: 3.0188 - acc: 0.4553\n",
      "Epoch 4/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: 1.7699 - acc: 0.3872\n",
      "Epoch 5/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: 0.9326 - acc: 0.2809\n",
      "Epoch 6/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: 0.4321 - acc: 0.2213\n",
      "Epoch 7/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: 0.1122 - acc: 0.1660\n",
      "Epoch 8/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -0.1412 - acc: 0.1489\n",
      "Epoch 9/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -0.3912 - acc: 0.1277\n",
      "Epoch 10/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -0.6104 - acc: 0.1149\n",
      "Epoch 11/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -0.8169 - acc: 0.0851\n",
      "Epoch 12/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: -1.0061 - acc: 0.0766\n",
      "Epoch 13/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: -1.1591 - acc: 0.0766\n",
      "Epoch 14/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -1.2996 - acc: 0.0766\n",
      "Epoch 15/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: -1.4487 - acc: 0.0723\n",
      "Epoch 16/40\n",
      "235/235 [==============================] - 0s 68us/step - loss: -1.5838 - acc: 0.0723\n",
      "Epoch 17/40\n",
      "235/235 [==============================] - 0s 34us/step - loss: -1.7186 - acc: 0.0723\n",
      "Epoch 18/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -1.8557 - acc: 0.0766\n",
      "Epoch 19/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -1.9752 - acc: 0.0723\n",
      "Epoch 20/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -2.0829 - acc: 0.0681\n",
      "Epoch 21/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -2.1997 - acc: 0.0681\n",
      "Epoch 22/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -2.2865 - acc: 0.0809\n",
      "Epoch 23/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -2.3762 - acc: 0.0809\n",
      "Epoch 24/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -2.4638 - acc: 0.0851\n",
      "Epoch 25/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -2.5635 - acc: 0.0936\n",
      "Epoch 26/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -2.6403 - acc: 0.0936\n",
      "Epoch 27/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -2.7126 - acc: 0.1021\n",
      "Epoch 28/40\n",
      "235/235 [==============================] - 0s 34us/step - loss: -2.7762 - acc: 0.1021\n",
      "Epoch 29/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: -2.8367 - acc: 0.1021\n",
      "Epoch 30/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: -2.8711 - acc: 0.1064\n",
      "Epoch 31/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -2.9262 - acc: 0.1106\n",
      "Epoch 32/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -2.9814 - acc: 0.1106\n",
      "Epoch 33/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -3.0157 - acc: 0.1106\n",
      "Epoch 34/40\n",
      "235/235 [==============================] - 0s 38us/step - loss: -3.0610 - acc: 0.1191\n",
      "Epoch 35/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -3.1023 - acc: 0.1191\n",
      "Epoch 36/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -3.1492 - acc: 0.1191\n",
      "Epoch 37/40\n",
      "235/235 [==============================] - 0s 34us/step - loss: -3.1872 - acc: 0.1149\n",
      "Epoch 38/40\n",
      "235/235 [==============================] - 0s 42us/step - loss: -3.2254 - acc: 0.1234\n",
      "Epoch 39/40\n",
      "235/235 [==============================] - 0s 47us/step - loss: -3.2711 - acc: 0.1149\n",
      "Epoch 40/40\n",
      "235/235 [==============================] - 0s 34us/step - loss: -3.2993 - acc: 0.1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5da8c4d68>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_xs, train_ys, epochs=40, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
